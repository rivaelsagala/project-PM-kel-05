{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e143e7b9-e09f-49fa-ba85-89d40c819994",
   "metadata": {},
   "source": [
    "## Mempersiapkan variabel global untuk training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9dc35c-cba7-46ca-9fbd-055047ed2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd36f0b9-edad-45a4-94ea-1c3e26f5d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter input untuk network\n",
    "dim = (640, 640)           # Sesuaikan dengan ukuran gambar dari dataset Roboflow\n",
    "channel = (3, )            # RGB channel\n",
    "input_shape = dim + channel\n",
    "# Batch size\n",
    "batch_size = 8             # Gunakan batch size yang lebih kecil jika GPU terbatas\n",
    "# Epoch\n",
    "epoch = 10                 # Tetap 10 untuk eksperimen awal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b42dc5-738e-4997-8a0c-ff0c9c009e5f",
   "metadata": {},
   "source": [
    "## Membuat dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8a110a-a300-4994-8cf7-268730b7805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc11977-1281-44ed-b3dd-2e33e209386a",
   "metadata": {},
   "source": [
    "## Mendefinisikan Data |Generatornya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfea643-18a7-4e54-bb3d-70930c46bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train/',\n",
    "    target_size=(640, 640),   # Ukuran input gambar\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Sesuaikan dengan tipe label\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'dataset/validation/',\n",
    "    target_size=(640, 640),   # Ukuran input gambar\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test/',\n",
    "    target_size=(640, 640),   # Ukuran input gambar\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1fa83-66cd-4f87-b58a-578a641ba32b",
   "metadata": {},
   "source": [
    "## Mendefinisikan asal folder sumber file berasal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b681a4f-5e2d-442d-b2f1-7a6af4fc2a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 601 images belonging to 3 classes.\n",
      "Found 76 images belonging to 3 classes.\n",
      "Found 75 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "img_height = 150\n",
    "img_width = 150\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train/',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'dataset/validation/',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test/',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307858c6-694e-4b61-8fa3-abc27e6ccb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'mujahir', 1: 'red_devil', 2: 'sepat'}\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan labels dari generator\n",
    "labels = train_generator.class_indices\n",
    "# Membalik key-value pairs agar index menjadi key dan nama kelas menjadi value\n",
    "labels = {v: k for k, v in labels.items()}\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e28bce-c3ea-4eb4-a8a7-78ee0eea3b0f",
   "metadata": {},
   "source": [
    "## Transformasi data generator menjadi tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a938799-4c58-4981-b7f4-4a6708dfb939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M S I\\AppData\\Local\\Temp\\ipykernel_22672\\2227134156.py:4: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\M S I\\AppData\\Local\\Temp\\ipykernel_22672\\2227134156.py:4: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def tf_data_generator(generator, input_shape):\n",
    "    num_class = generator.num_classes\n",
    "    tf_generator = tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=([None\n",
    "                        , input_shape[0]\n",
    "                        , input_shape[1]\n",
    "                        , input_shape[2]]\n",
    "                       ,[None, num_class])\n",
    "    )\n",
    "    return tf_generator\n",
    "train_data = tf_data_generator(train_generator, input_shape)\n",
    "test_data = tf_data_generator(test_generator, input_shape)\n",
    "val_data = tf_data_generator(val_generator, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b24f74-de22-42e2-9aa6-076855217df8",
   "metadata": {},
   "source": [
    "## Membuat Struktur CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba2d8df-e988-4ac6-8f7c-23bd8fb458f3",
   "metadata": {},
   "source": [
    "## Manualy define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f7a823-20fe-459f-a7af-87e36da161aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6962d8-3f41-4fe5-ab72-e5a9f8eb5fcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Sesuaikan dengan dataset Anda\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Definisi model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m----> 9\u001b[0m     Input(shape\u001b[38;5;241m=\u001b[39minput_shape),\n\u001b[0;32m     10\u001b[0m     Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     11\u001b[0m     Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     12\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m     13\u001b[0m     Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     14\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     15\u001b[0m     Dropout(\u001b[38;5;241m0.25\u001b[39m),\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m     Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     18\u001b[0m     Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     19\u001b[0m     Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m     20\u001b[0m     Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     21\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     22\u001b[0m     Dropout(\u001b[38;5;241m0.25\u001b[39m),\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m     Flatten(),\n\u001b[0;32m     25\u001b[0m     Dense(\u001b[38;5;241m512\u001b[39m),\n\u001b[0;32m     26\u001b[0m     Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     27\u001b[0m     Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m     28\u001b[0m     Dense(num_class),\n\u001b[0;32m     29\u001b[0m     Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m ])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompiling Model.......\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "# Jumlah kelas\n",
    "num_class = 3  \n",
    "\n",
    "# Ukuran input gambar (640x640 sesuai dengan dataset Roboflow)\n",
    "input_shape = (640, 640, 3)\n",
    "\n",
    "# Definisi model\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Conv2D(128, (3, 3), padding='same'),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, (3, 3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), padding='same'),\n",
    "    Activation('relu'),\n",
    "    Conv2D(64, (3, 3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_class),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "print('Compiling Model.......')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ef62f-3f2b-4995-8387-6def37525d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed193e-2fc5-4a2f-b0ec-e7dea8af5bcf",
   "metadata": {},
   "source": [
    "## Using Pre-trained model / Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b45b10-3f0f-452e-ba04-2147da92a22b",
   "metadata": {},
   "source": [
    "## Prebuild model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edbf919-7a28-433d-8bd9-ca8d6c769122",
   "metadata": {},
   "source": [
    "## Build Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdee91-02cc-4938-b661-b2701e553a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# get base models\n",
    "input_shape = (150, 150, 3)\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    classes=num_class\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d02c3-c3ca-4b68-a0ee-b88ed3854320",
   "metadata": {},
   "source": [
    "## Add top layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b367f-09a4-4bd1-b15f-0a704ebc7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503a44d-d2cf-4916-9ea8-627bfdf53f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom layers\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "predictions = layers.Dense(num_class, activation=\"softmax\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdf757-7c80-4139-8a8a-e4a52ffee901",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25272bac-ceea-4931-b4f3-cdb0d7c1d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "print('Compiling Model.......')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba49e2e-7e6e-4f6f-9d85-9678e61fb036",
   "metadata": {},
   "source": [
    "## Effinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c1401-c997-4f6e-a30a-18d1223ab668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -U --pre efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50146fc8-19f4-4dcf-8b64-a03ba3866b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.tfkeras import EfficientNetB1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddc9272-dbe4-4696-8729-1eece7ee0764",
   "metadata": {},
   "source": [
    "## Build Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffd819-6010-4d30-830a-d8fcb4ae499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get base models\n",
    "base_model = EfficientNetB1(\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "    weights='noisy-student',\n",
    "    classes=num_class,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e354e-d2da-4078-a4d8-69d95260ef37",
   "metadata": {},
   "source": [
    "## Add top network layer to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8ea9f-b551-460b-ae7f-a4cc3816c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f2e2d-53f6-4d4a-9da2-220196e3e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom layers\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "predictions = layers.Dense(num_class, activation=\"softmax\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb969439-5b54-4a0c-96a7-b3b8bccaccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c5ea8-73c1-4ee6-a531-b2ddeddb3755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "print('Compiling Model.......')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafc919-0cda-468b-8df0-b1de4bbcaeab",
   "metadata": {},
   "source": [
    "## Visualize The final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490bd62-4ca2-404d-9650-b4b871be7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d60acc-cd92-478b-bfb8-bef96eecc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_viz = tf.keras.utils.plot_model(model,\n",
    "                          to_file='model.png',\n",
    "                          show_shapes=True,\n",
    "                          show_layer_names=True,\n",
    "                          rankdir='TB',\n",
    "                          expand_nested=True,\n",
    "                          dpi=55)\n",
    "model_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9115be-0e35-413c-a491-6703589e94b6",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba70d2-6a13-491a-ac8b-6985052b6869",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,  # gunakan variabel epochs, bukan EPOCH\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2384d-4dc6-4811-b846-4542eedfca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2  # Jumlah epoch untuk training\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_data,  # Pastikan 'train_data' sudah didefinisikan\n",
    "    steps_per_epoch=len(train_generator),  # Atau sesuai kebutuhan Anda\n",
    "    epochs=epochs,  # Gunakan variabel epochs\n",
    "    validation_data=val_data,  # Pastikan 'val_data' sudah didefinisikan\n",
    "    validation_steps=len(val_generator),  # Atau sesuai kebutuhan Anda\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d8e0b-0704-4f75-a493-9cfe16068a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
